{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the Keras model and weights to a TensorFlow SavedModel '.pb' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import tempfile\n",
    "import yaml\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import quilt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import mask_lib as mlib\n",
    "\n",
    "root_dir = Path(\"/home/hadim/.data/Neural_Network/Mask-RCNN/Microtubules/\")\n",
    "\n",
    "model_dir = root_dir / \"logs\"\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "saved_model_dir = root_dir / \"saved_model\"\n",
    "saved_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_dir = root_dir / \"Data\"\n",
    "\n",
    "model_name = \"microtubule_coco_512\"\n",
    "\n",
    "quilt_user = \"hadim\"\n",
    "quilt_model_name = \"mask_rcnn_tf_model_in_vitro_microtubule\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = mlib.MicrotubuleInferenceConfig()\n",
    "config.set_images_per_gpu(1)\n",
    "\n",
    "model = mlib.load_model(model_dir, config, mode=\"inference\")\n",
    "mlib.load_weights(model, init_with=\"last\", model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export model to Tensoflow .pb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model_path = saved_model_dir / f\"tf_model_{model_name}.pb\"\n",
    "zip_tf_model_path = saved_model_dir / f\"{tf_model_path.stem}.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 384 variables.\n",
      "Converted 384 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/hadim/.data/Neural_Network/Mask-RCNN/Microtubules/saved_model/tf_model_microtubule_coco_512.pb')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlib.export_to_tensorflow(model, tf_model_path, tf_model_zip_path=zip_tf_model_path)\n",
    "tf_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add pre- and post-processing models to the ZIP file\n",
    "\n",
    "Both models have been created with this notebook: [`5_Build_Processing_Graph.ipynb`](5_Build_Processing_Graph.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_model_path = saved_model_dir / \"preprocessing_graph.pb\"\n",
    "postprocessing_model_path = saved_model_dir / \"postprocessing_graph.pb\"\n",
    "\n",
    "with zipfile.ZipFile(zip_tf_model_path, \"a\") as z:\n",
    "    z.write(preprocessing_model_path, arcname=preprocessing_model_path.name)\n",
    "    z.write(postprocessing_model_path, arcname=postprocessing_model_path.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add parameters to the ZIP file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'microtubule',\n",
       " 'class_names': ['BG', 'microtubule'],\n",
       " 'image_min_dimension': 100,\n",
       " 'image_max_dimension': 512,\n",
       " 'minimum_scale': 1.0,\n",
       " 'mean_pixels': [43.53, 39.56, 48.22],\n",
       " 'class_ids': [0.0, 0.0],\n",
       " 'backbone_strides': [4, 8, 16, 32, 64],\n",
       " 'rpn_anchor_scales': [8, 16, 32, 64, 128],\n",
       " 'rpn_anchor_ratios': [0.5, 1, 2],\n",
       " 'rpn_anchor_stride': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {}\n",
    "parameters[\"model_name\"] = config.NAME\n",
    "parameters[\"class_names\"] = config.CLASS_NAMES\n",
    "parameters[\"image_min_dimension\"] = config.IMAGE_MIN_DIM\n",
    "parameters[\"image_max_dimension\"] = config.IMAGE_MAX_DIM\n",
    "parameters[\"minimum_scale\"] = config.IMAGE_MIN_SCALE\n",
    "parameters[\"mean_pixels\"] = config.MEAN_PIXEL.tolist()\n",
    "parameters[\"class_ids\"] = np.zeros(len(config.CLASS_NAMES)).tolist()\n",
    "parameters[\"backbone_strides\"] = list(config.BACKBONE_STRIDES)\n",
    "parameters[\"rpn_anchor_scales\"] = list(config.RPN_ANCHOR_SCALES)\n",
    "parameters[\"rpn_anchor_ratios\"] = list(config.RPN_ANCHOR_RATIOS)\n",
    "parameters[\"rpn_anchor_stride\"] = config.RPN_ANCHOR_STRIDE\n",
    "    \n",
    "_, temp_path = tempfile.mkstemp()\n",
    "\n",
    "with open(temp_path, \"w\") as f:\n",
    "    f.write(yaml.dump(parameters))\n",
    "    \n",
    "with zipfile.ZipFile(zip_tf_model_path, \"a\") as z:\n",
    "    z.write(temp_path, arcname=\"parameters.yml\")\n",
    "    \n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add description to the ZIP file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_path = data_dir / \"DESCRIPTION.md\"\n",
    "    \n",
    "with zipfile.ZipFile(zip_tf_model_path, \"a\") as z:\n",
    "    z.write(description_path, arcname=\"DESCRIPTION_DATASET.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add readme and license to the ZIP file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy README.md and LICENSE.txt to the ZIP archive.\n",
    "\n",
    "with zipfile.ZipFile(zip_tf_model_path, \"a\") as z:\n",
    "    z.write(saved_model_dir / \"README.md\", arcname=\"README.md\")\n",
    "    z.write(saved_model_dir / \"LICENSE.txt\", arcname=\"LICENSE.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the model as a Quilt data package\n",
    "\n",
    "See the [Quilt website](https://quiltdata.com/) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the archive to a temp folder\n",
    "\n",
    "temp_path = tempfile.mkdtemp()\n",
    "\n",
    "with zipfile.ZipFile(zip_tf_model_path, \"r\") as z:\n",
    "    z.extractall(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferring 'transform: id' for parameters.yml\n",
      "Registering /tmp/tmpr5zjavod/parameters.yml...\n",
      "Inferring 'transform: id' for README.md\n",
      "Registering /tmp/tmpr5zjavod/README.md...\n",
      "Inferring 'transform: id' for preprocessing_graph.pb\n",
      "Registering /tmp/tmpr5zjavod/preprocessing_graph.pb...\n",
      "Inferring 'transform: id' for model.pb\n",
      "Registering /tmp/tmpr5zjavod/model.pb...\n",
      "Inferring 'transform: id' for LICENSE.txt\n",
      "Registering /tmp/tmpr5zjavod/LICENSE.txt...\n",
      "Inferring 'transform: id' for postprocessing_graph.pb\n",
      "Registering /tmp/tmpr5zjavod/postprocessing_graph.pb...\n",
      "Built hadim/mask_rcnn_tf_model_in_vitro_microtubule successfully.\n"
     ]
    }
   ],
   "source": [
    "# Build the data package\n",
    "quilt.build(quilt_user + \"/\" + quilt_model_name, path=temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching upload URLs from the registry...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0.00/179M [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading 6 fragments (179055726 bytes before compression)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 179M/179M [01:13<00:00, 2.44MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading package metadata...\n",
      "Updating the 'latest' tag...\n",
      "Push complete. hadim/mask_rcnn_tf_model_in_vitro_microtubule is live:\n",
      "https://quiltdata.com/package/hadim/mask_rcnn_tf_model_in_vitro_microtubule\n"
     ]
    }
   ],
   "source": [
    "# You need to execute quilt.login() first.\n",
    "quilt.push(quilt_user + \"/\" + quilt_model_name, is_public=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the temp folder\n",
    "shutil.rmtree(temp_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nn]",
   "language": "python",
   "name": "conda-env-nn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

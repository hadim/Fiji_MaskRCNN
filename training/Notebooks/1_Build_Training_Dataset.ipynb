{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the dataset\n",
    "\n",
    "- This notebook depends highly on the kind of dataset you want to run the training. The output is a folder (`data_dir`) which contains all of your training dataset as well as the annotations.\n",
    "- The current [`2_Train.ipynb`](2_Train.ipynb) notebook uses the [`MicrotubuleDataset`](../mask_lib/dataset.py) class to load the data from within the training dataset folder (`data_dir`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from simuscope import Model\n",
    "\n",
    "root_dir = Path(\"/home/hadim/.data/Neural_Network/Mask-RCNN/Microtubules/\")\n",
    "data_dir = root_dir / \"data_small\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the data folder\n",
    "[os.remove(fname) for fname in data_dir.glob(\"*\")]\n",
    "data_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate fake microtubule images\n",
    "\n",
    "We generate microtubule images over a wide range of SNR (signal over noise ratio) and number of microtubules per image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (1, 1, 512, 512)\n",
      "Image memory size: 2.00 MB\n",
      "Channels: ['channel_1']\n",
      "Objects: [<simuscope.builder.object_builder.microtubule_builder.SimpleMicrotubuleBuilder object at 0x7fd5d2b7b668>]\n",
      "\n",
      "168\n"
     ]
    }
   ],
   "source": [
    "model_name = \"simple_microtubule\"\n",
    "model = Model.load_model(model_name)\n",
    "\n",
    "model.microscope.camera.chip_size_height = 512\n",
    "model.microscope.camera.chip_size_width = 512\n",
    "model.acquisition.n_frames = 1\n",
    "\n",
    "model.acquisition.channels.pop(\"channel_2\")\n",
    "\n",
    "builder = model.get_builder()\n",
    "print(builder)\n",
    "\n",
    "# Setup parameter ranges\n",
    "snr_range = np.arange(1.3, 4, 0.2)\n",
    "n_mts_range = np.arange(1, 60, 5)\n",
    "n = 1\n",
    "\n",
    "total_images = snr_range.shape[0] * n_mts_range.shape[0] * n\n",
    "print(total_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=8)]: Done 168 out of 168 | elapsed:   16.4s finished\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset\n",
    "\n",
    "def create(*args):\n",
    "    \n",
    "    snr, n_mts = args[0]\n",
    "    \n",
    "    model.acquisition.channels[\"channel_1\"].snr = snr\n",
    "\n",
    "    mt_obj = model.objects[\"microtubule\"]\n",
    "    mt_obj.parameters[\"nucleation_rate\"][\"parameters\"][\"loc\"] = 0\n",
    "    mt_obj.parameters[\"n_microtubules\"][\"parameters\"][\"loc\"] = n_mts\n",
    "    mt_obj.parameters[\"initial_length\"][\"parameters\"][\"loc\"] = 6\n",
    "    mt_obj.parameters[\"initial_length\"][\"parameters\"][\"scale\"] = 5\n",
    "\n",
    "    for i in range(n):\n",
    "        basename = f\"image_snr_{snr:.1f}_n-mts_{n_mts}_id_{i}\"\n",
    "\n",
    "        builder = model.get_builder()\n",
    "        images = builder.build(keep_images=False)\n",
    "        builder.save(str(data_dir / basename))\n",
    "    \n",
    "parameters = list(itertools.product(snr_range, n_mts_range))\n",
    "p = joblib.Parallel(n_jobs=8, verbose=1)\n",
    "_ = p(map(joblib.delayed(create), parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy Manually Annotated Dataset\n",
    "\n",
    "Here we copy a manually annotated dataset to the final training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_data_dir = root_dir / \"Manual Training Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nn]",
   "language": "python",
   "name": "conda-env-nn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the dataset\n",
    "\n",
    "- This notebook depends highly on the kind of dataset you want to run the training. The output is a folder (`data_dir`) which contains all of your training dataset as well as the annotations.\n",
    "- The current [`2_Train.ipynb`](2_Train.ipynb) notebook uses the [`MicrotubuleDataset`](../mask_lib/dataset.py) class to load the data from within the training dataset folder (`data_dir`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import datetime\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from simuscope import Model\n",
    "\n",
    "root_dir = Path(\"/home/hadim/.data/Neural_Network/Mask-RCNN/Microtubules/\")\n",
    "data_dir = root_dir / \"Data\"\n",
    "description_path = data_dir / \"DESCRIPTION.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the data folder\n",
    "[os.remove(fname) for fname in data_dir.glob(\"*\")]\n",
    "data_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate fake microtubule images\n",
    "\n",
    "We generate microtubule images over a wide range of SNR (signal over noise ratio) and number of microtubules per image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (1, 1, 512, 512)\n",
      "Image memory size: 2.00 MB\n",
      "Channels: ['channel_1']\n",
      "Objects: [<simuscope.builder.object_builder.microtubule_builder.SimpleMicrotubuleBuilder object at 0x7f0693793550>]\n",
      "\n",
      "168\n"
     ]
    }
   ],
   "source": [
    "model_name = \"simple_microtubule\"\n",
    "model = Model.load_model(model_name)\n",
    "\n",
    "model.acquisition.n_frames = 1\n",
    "model.acquisition.channels.pop(\"channel_2\")\n",
    "\n",
    "builder = model.get_builder()\n",
    "print(builder)\n",
    "\n",
    "# Setup parameter ranges\n",
    "snr_range = np.arange(1.3, 4, 0.2)\n",
    "n_mts_range = np.arange(1, 60, 5)\n",
    "n = 1\n",
    "\n",
    "total_images = snr_range.shape[0] * n_mts_range.shape[0] * n\n",
    "print(total_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=8)]: Done 168 out of 168 | elapsed:   19.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset\n",
    "\n",
    "def create(*args):\n",
    "    \n",
    "    snr, n_mts = args[0]\n",
    "    \n",
    "    model.acquisition.channels[\"channel_1\"].snr = snr\n",
    "\n",
    "    mt_obj = model.objects[\"microtubule\"]\n",
    "    mt_obj.parameters[\"nucleation_rate\"][\"parameters\"][\"loc\"] = 0\n",
    "    mt_obj.parameters[\"n_microtubules\"][\"parameters\"][\"loc\"] = n_mts\n",
    "    mt_obj.parameters[\"initial_length\"][\"parameters\"][\"loc\"] = 6\n",
    "    mt_obj.parameters[\"initial_length\"][\"parameters\"][\"scale\"] = 5\n",
    "\n",
    "    for i in range(n):\n",
    "        basename = f\"image_snr_{snr:.1f}_n-mts_{n_mts}_id_{i}\"\n",
    "\n",
    "        random_size = np.random.randint(512, 1200)\n",
    "        model.microscope.camera.chip_size_height = random_size\n",
    "        model.microscope.camera.chip_size_width = random_size\n",
    "        \n",
    "        builder = model.get_builder()\n",
    "        images = builder.build(keep_images=False)\n",
    "        builder.save(str(data_dir / basename))\n",
    "    \n",
    "parameters = list(itertools.product(snr_range, n_mts_range))\n",
    "p = joblib.Parallel(n_jobs=8, verbose=1)\n",
    "_ = p(map(joblib.delayed(create), parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy Manually Annotated Dataset\n",
    "\n",
    "Here we copy a manually annotated dataset to the final training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import read_roi\n",
    "\n",
    "manual_data_dir = root_dir / \"Manual Training Dataset\"\n",
    "processed_data_dir = root_dir / \"Manual Training Dataset/Processed\"\n",
    "manual_description_path = manual_data_dir / \"DESCRIPTION.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [fname.with_suffix(\".tif\") for fname in processed_data_dir.glob(\"*.zip\")]\n",
    "for fname in fnames:\n",
    "    new_fname = shutil.copy(fname, data_dir)\n",
    "    json_path = Path(new_fname).with_suffix(\".json\")\n",
    "    \n",
    "    # Convert ZIP rois to JSON rois\n",
    "    rois = read_roi.read_roi_zip(fname.with_suffix(\".zip\"))\n",
    "\n",
    "    json_roi = {\"microtubule\": {}}\n",
    "    mt = json_roi[\"microtubule\"]\n",
    "    mt[\"end_x\"] = {}\n",
    "    mt[\"end_y\"] = {}\n",
    "    mt[\"frame\"] = {}\n",
    "    mt[\"mt_id\"] = {}\n",
    "    mt[\"start_x\"] = {}\n",
    "    mt[\"start_y\"] = {}\n",
    "    mt[\"type\"] = {}\n",
    "\n",
    "    for i, (roi_name, roi) in enumerate(rois.items()):\n",
    "        mt[\"type\"][str(i)] = \"seed\"\n",
    "        mt[\"frame\"][str(i)] = 0\n",
    "        mt[\"mt_id\"][str(i)] = i\n",
    "        \n",
    "        if \"x1\" in roi.keys():\n",
    "            mt[\"end_x\"][str(i)] = roi[\"x2\"]\n",
    "            mt[\"end_y\"][str(i)] = roi[\"y2\"]\n",
    "            mt[\"start_y\"][str(i)] = roi[\"y1\"]\n",
    "            mt[\"start_x\"][str(i)] = roi[\"x1\"]\n",
    "        else:\n",
    "            mt[\"end_x\"][str(i)] = roi[\"x\"][-1]\n",
    "            mt[\"end_y\"][str(i)] = roi[\"y\"][-1]\n",
    "            mt[\"start_y\"][str(i)] = roi[\"y\"][0]\n",
    "            mt[\"start_x\"][str(i)] = roi[\"x\"][0]\n",
    "\n",
    "    json.dump(json_roi, open(json_path, \"w\"), indent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description file\n",
    "\n",
    "Add to `DESCRIPTION.md` a description about this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_str = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "with open(description_path, \"a\") as f:\n",
    "    f.write(\"Description of the Training Dataset\\n\\n\")\n",
    "    f.write(f\"- Date: {date_str}\\n\\n\")\n",
    "    f.write(f\"- Manually Annotated Dataset ({len(fnames)} images):\\n\\n\")\n",
    "    \n",
    "    with open(manual_description_path) as d:\n",
    "        desc = d.readlines()\n",
    "        f.write(\"\\n\".join([\"\\t\" + line for line in desc]))\n",
    "    \n",
    "    f.write(f\"\\n\")\n",
    "    f.write(f\"- Simulated Dataset Parameters using the Python library `simuscope` ({total_images} images):\\n\\n\")\n",
    "    f.write(f\"```yaml\\n\")\n",
    "    f.write(f\"{str(model)}\\n\")\n",
    "    f.write(f\"```\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nn]",
   "language": "python",
   "name": "conda-env-nn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
